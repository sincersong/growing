## 模型融合

- [ ] 对于多种调参完成的模型进行模型融合。

一、融合方法：

模型融合是比赛后期一个重要的环节，大体来说有如下的类型方式:

- 简单加权融合:
  - 回归（分类概率）：算术平均融合（Arithmetic mean），几何平均融合（Geometric mean）
  - 分类：投票（Voting)
  - 综合：排序融合(Rank averaging)，log融合

- stacking/blending:
  - 构建多层模型，并利用预测结果再拟合预测。

- boosting/bagging（在xgboost，Adaboost,GBDT中已经用到）:
  - 多树的提升方法

二、Stacking相关理论介绍：

 1) stacking： 简单来说 stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。

![img](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448793231_6TygjXwjNb.jpg)

（stacking相当于学习器的学习器，将之前的所有结果汇集，训练生成结果）

​		将个体学习器结合在一起的时候使用的方法叫做结合策略。对于分类问题，我们可以使用投票法来选择输出最多的类。对于回归问题，我们可以将分类器输出的结果求平均值。

​		上面说的投票法和平均法都是很有效的结合策略，还有一种结合策略是使用另外一个机器学习算法来将个体机器学习器的结果结合在一起，这个方法就是Stacking。

​		在stacking方法中，我们把个体学习器叫做初级学习器，用于结合的学习器叫做次级学习器或元学习器（meta-learner），次级学习器用于训练的数据叫做次级训练集。次级训练集是在训练集上用初级学习器得到的。

在不同模型预测的结果基础上再加一层模型，进行再训练，从而得到模型最终的预测。

2）Stacking本质上就是这么直接的思路，但是直接这样有时对于**如果训练集和测试集分布不那么一致的情况下是有一点问题的**，其问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问**会导致一定的模型过拟合训练集**，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了**如何降低再训练的过拟合性**，这里我们一般有两种方法。

- 次级模型尽量选择简单的线性模型
- 利用K折交叉验证

